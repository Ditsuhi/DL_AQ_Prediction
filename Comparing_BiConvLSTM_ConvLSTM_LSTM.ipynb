{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparing_BiConvLSTM_ConvLSTM_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPV/Ff60VeN9oUOXnvxXsuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ditsuhi/Nitrogen_Dioxide_Prediction/blob/main/Comparing_BiConvLSTM_ConvLSTM_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVZVoVBz04Ol"
      },
      "outputs": [],
      "source": [
        "# import all required libraries\n",
        "\n",
        "import zipfile\n",
        "from glob import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.interpolate import NearestNDInterpolator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import ConvLSTM2D, BatchNormalization\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import  Conv2D \n",
        "from time import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafr_2019 = pd.read_csv('/content/Madrid_FIN_WDUpdated_2019.csv', index_col='Unnamed: 0')\n",
        "datafr_2020 = pd.read_csv('/content/Madrid_FIN_WDUpdated_2020.csv', index_col='Unnamed: 0')"
      ],
      "metadata": {
        "id": "r71E87s41CUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafr_new_2019=datafr_2019[['NO2', 'intensidad', 'ocupacion', 'windSpeed', 'Pressure', 'SolarRad',\n",
        "       ' Temp', ' Humidity', 'windDir_Categ_east', 'windDir_Categ_north', 'windDir_Categ_northeast',\n",
        "       'windDir_Categ_northwest', 'windDir_Categ_south',  'windDir_Categ_southeast', 'windDir_Categ_southwest',\n",
        "       'windDir_Categ_west'\n",
        "       ]]\n",
        "     \n",
        "\n",
        "datafr_new_2020=datafr_2020[['NO2', 'intensidad', 'ocupacion', 'windSpeed', 'Pressure', 'SolarRad',\n",
        "       'Temp', 'Humidity', 'windDir_Categ_east', 'windDir_Categ_north', 'windDir_Categ_northeast',\n",
        "       'windDir_Categ_northwest', 'windDir_Categ_south',  'windDir_Categ_southeast', 'windDir_Categ_southwest',\n",
        "       'windDir_Categ_west'\n",
        "       ]]"
      ],
      "metadata": {
        "id": "PQ0I-bWs1Nz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_np_2019 = np.asarray(datafr_new_2019)\n",
        "round_data_2019 = data_np_2019.reshape(-1, 340, 16)\n",
        "data_np_2020 = np.asarray(datafr_new_2020)\n",
        "round_data_2020 = data_np_2020.reshape(-1, 340,  16)\n",
        "mut_data_2019= round_data_2019[:, :, :]\n",
        "mut_data_2020= round_data_2020[:, :,  :]\n",
        "mut_data_2020_Val = mut_data_2020[0:2184, :, :]\n",
        "mut_data_2020_test = mut_data_2020[2184::, :, :]"
      ],
      "metadata": {
        "id": "9dcSYXzu1nWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset to X and y (dependent and independent)\n",
        "\n",
        "def split_sequence(sequence, time_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "   \n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + 6\n",
        "    \n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix+time_steps > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern    \n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix: end_ix+time_steps]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)\n",
        " \n",
        "\n",
        "# define input sequence\n",
        "raw_seq_2019 = mut_data_2019\n",
        "raw_seq_2020_val= mut_data_2020_Val\n",
        "raw_seq_2020_test= mut_data_2020_test\n",
        "# choose a number of time steps (there are two case of time lags: 6-hour and 6-hour)\n",
        "time_steps = 6\n",
        "X_train_notNorm, y_train = split_sequence(raw_seq_2019, time_steps)\n",
        "X_val_notNorm, y_val = split_sequence(raw_seq_2020_val, time_steps)\n",
        "X_test_notNorm, y_test = split_sequence(raw_seq_2020_test, time_steps)\n",
        "\n",
        "#X_train_notNorm, X_test_notNorm, y_train_notNorm, y_test_notNorm = train_test_split(X, y, test_size=0.2, shuffle = False)"
      ],
      "metadata": {
        "id": "oUGfGNjH10xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to normalise train data using MinMaxScaler\n",
        "number_selected_columns =16\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1), copy = False)\n",
        "X_train_Normalised = X_train_notNorm.reshape(-1, number_selected_columns)\n",
        "X_val_Normalised = X_val_notNorm.reshape(-1, number_selected_columns)\n",
        "X_test_Normalised = X_test_notNorm.reshape(-1, number_selected_columns)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_Normalised)\n",
        "X_val_scaled = scaler.transform(X_val_Normalised)\n",
        "X_test_scaled = scaler.transform(X_test_Normalised)\n",
        "\n",
        "X_train = X_train_scaled.reshape(X_train_notNorm.shape[0], X_train_notNorm.shape[1], X_train_notNorm.shape[2], X_train_notNorm.shape[3])\n",
        "X_val = X_val_scaled.reshape(X_val_notNorm.shape[0], X_val_notNorm.shape[1], X_val_notNorm.shape[2], X_val_notNorm.shape[3])\n",
        "X_test = X_test_scaled.reshape(X_test_notNorm.shape[0], X_test_notNorm.shape[1], X_test_notNorm.shape[2], X_test_notNorm.shape[3])"
      ],
      "metadata": {
        "id": "uZWaGuFT15U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convLSTM\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 20, 17*number_selected_columns, 1))\n",
        "y_train_reshaped = y_train.reshape((y_train.shape[0], y_train.shape[1], 20, 17*number_selected_columns, 1))\n",
        "X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 20, 17*number_selected_columns, 1))\n",
        "y_val_reshaped = y_val.reshape(y_val.shape[0], y_val.shape[1], 20, 17*number_selected_columns, 1)\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 20, 17*number_selected_columns, 1))\n",
        "y_test_reshaped = y_test.reshape(y_test.shape[0], y_test.shape[1], 20, 17*number_selected_columns, 1)"
      ],
      "metadata": {
        "id": "3LyQ8Msl19w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the architecture of the proposed model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import ConvLSTM2D, Dropout\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "def create_model(number_selected_columns=7, optimizer=opt, kernel_size=(3, 3), filters=16, merge_mode=\"concat\", dropout_rate=0.2):\n",
        "    \n",
        "    model = Sequential()    \n",
        "    model.add(Bidirectional(ConvLSTM2D(input_shape=(None, 20, 17*number_selected_columns, 1),  filters=filters,  kernel_size=kernel_size, padding=\"same\", return_sequences=True), merge_mode=merge_mode))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))   \n",
        "    model.add(Bidirectional(ConvLSTM2D(filters=filters, kernel_size=kernel_size, padding=\"same\", return_sequences=True), merge_mode=merge_mode))    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate)) \n",
        "    model.add(Bidirectional(ConvLSTM2D(filters=filters,  kernel_size=kernel_size, padding=\"same\", return_sequences=True), merge_mode=merge_mode))     \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))            \n",
        "    model.add(Conv2D(filters=1, kernel_size=(1, 1), \n",
        "                activation='elu',\n",
        "                padding='same', data_format='channels_last'))\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    model.build(input_shape=(None,6,  20, 17*number_selected_columns, 1))    \n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "fOozHbcs2PM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = create_model()\n",
        "\n",
        "start = time()\n",
        "#code here\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=2)\n",
        "mymodel = mod.fit(X_train_reshaped, y_train_reshaped, epochs=50, verbose=2, validation_data=(X_val_reshaped, y_val_reshaped),  callbacks=[early_stopping])\n",
        "\n",
        "print(f'Time taken to run: {time() - start} seconds')"
      ],
      "metadata": {
        "id": "oQLyBdkX2R6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = mod.predict(X_test_reshaped, verbose=1)\n",
        "yhat_reshaped = yhat.reshape(-1,20*17*16)\n",
        "y_test_reshaped=  y_test_reshaped.reshape(-1,20*17*16)\n",
        "rsme = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
        "print('Test Score: %.2f RMSE' % (rmse))\n",
        "print('Test Score: %.2f MAE' % (mae))\n"
      ],
      "metadata": {
        "id": "VSnXZ43P2XFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vgQg5sjg2ui9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WV_6a0i12qMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import ConvLSTM2D, Dropout, BatchNormalization\n",
        "from  keras.regularizers import l2\n",
        "from keras.layers.convolutional import Conv3D, Conv2D\n",
        "\n",
        "\n",
        "def create_model_conv(number_selected_columns=16, optimizer='adam', kernel_size=(5, 5), filters=32, dropout_rate=0.2, init_mode=\"glorot_uniform\"):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(ConvLSTM2D(input_shape=(None,  20, 17*number_selected_columns, 1),  filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(BatchNormalization())    \n",
        "    model.add(ConvLSTM2D(filters=filters,  kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))   \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    #model.add(Dropout(dropout_rate))  \n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(ConvLSTM2D(filters=filters,  kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    #model.add(Dropout(dropout_rate))   \n",
        "    #model.add(BatchNormalization())\n",
        "    #model.add(ConvLSTM2D(filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=1, kernel_size=(1, 1),\n",
        "                   activation='relu',\n",
        "                   padding='same', data_format='channels_last'))         \n",
        "   #model.add(ConvLSTM2D(filters=1, kernel_initializer=init_mode, kernel_size=(1, 1), activation='relu'))\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "   \n",
        "    \n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7AuEcfft2qTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modConv = create_model_conv()\n",
        "start = time()\n",
        "#code here\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
        "my_model = modConv.fit(X_train_reshaped, y_train_reshaped,  epochs=50, verbose=2, validation_data=(X_val_reshaped, y_val_reshaped),  callbacks=[es])\n",
        "\n",
        "print(f'Time taken to run: {time() - start} seconds')"
      ],
      "metadata": {
        "id": "Jcn-EL6L2tyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = modConv.predict(X_test_reshaped, verbose=1)\n",
        "yhat_reshaped = yhat.reshape(-1,20*17*16)\n",
        "y_test_reshaped=  y_test_reshaped.reshape(-1,20*17*16)\n",
        "rsme = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
        "print('Test Score: %.2f RMSE' % (rmse))\n",
        "print('Test Score: %.2f MAE' % (mae))"
      ],
      "metadata": {
        "id": "zXma-FII3y71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nmZB_9r039hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VqxZ2OuL39nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lstm\n",
        "\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 340*number_selected_columns))\n",
        "y_train_reshaped = y_train.reshape((y_train.shape[0], y_train.shape[1], 340*number_selected_columns))\n",
        "X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 340*number_selected_columns))\n",
        "y_val_reshaped = y_val.reshape(y_val.shape[0], y_val.shape[1], 340*number_selected_columns)\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 340*number_selected_columns))\n",
        "y_test_reshaped = y_test.reshape(y_test.shape[0], y_test.shape[1], 340*number_selected_columns)"
      ],
      "metadata": {
        "id": "elPEmj4139qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense,  Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128,input_shape=(X_train.shape[1], 20*17*number_selected_columns) ))\n",
        "model.add(LSTM(2048, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(2048, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(layers.Flatten())\n",
        "model.add(Dense(340*number_selected_columns))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "76mmClum4BNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time()\n",
        "#code here\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=2)\n",
        "mymodel = model.fit(X_train_reshaped, y_train_reshaped, epochs=50, verbose=2, validation_data=(X_val_reshaped, y_val_reshaped),  callbacks=[early_stopping])\n",
        "\n",
        "print(f'Time taken to run: {time() - start} seconds')"
      ],
      "metadata": {
        "id": "_0j3Uqds4EOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(X_test_reshaped, verbose=1)\n",
        "yhat_reshaped = yhat.reshape(-1,20*17*16)\n",
        "y_test_reshaped=  y_test_reshaped.reshape(-1,20*17*16)\n",
        "rsme = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
        "print('Test Score: %.2f RMSE' % (rmse))\n",
        "print('Test Score: %.2f MAE' % (mae))"
      ],
      "metadata": {
        "id": "1oIo85q64SkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WHA0JYsg4iXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "te5kl0GD4lL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}